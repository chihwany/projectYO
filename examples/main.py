"""
ì¤‘ê³ ë‚˜ë¼ ìŠ¤í¬ë˜í¼ CLI
Usage: python main.py "ê²€ìƒ‰ì–´" [ì˜µì…˜]
"""

import argparse
import json
import sys
from ..scrapers.joongna_scraper import JoongnaScraper


def main():
    parser = argparse.ArgumentParser(
        description="ì¤‘ê³ ë‚˜ë¼ ë§¤ë¬¼ ê²€ìƒ‰ ìŠ¤í¬ë˜í¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python main.py "ì•„ì´í° 15"
  python main.py "ë§¥ë¶" --category 8 --sort recent
  python main.py "ê°¤ëŸ­ì‹œ" --min-price 100000 --max-price 500000
  python main.py "ì—ì–´íŒŸ" --json
  python main.py "ì•„ì´íŒ¨ë“œ" --pages 3
        """,
    )
    
    parser.add_argument("keyword", help="ê²€ìƒ‰í•  í‚¤ì›Œë“œ")
    parser.add_argument("--page", type=int, default=1, help="í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸: 1)")
    parser.add_argument("--pages", type=int, default=0, help="ì—¬ëŸ¬ í˜ì´ì§€ ê²€ìƒ‰ ì‹œ ìµœëŒ€ í˜ì´ì§€ ìˆ˜")
    parser.add_argument("--count", type=int, default=50, help="í•œ í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 50)")
    parser.add_argument(
        "--sort",
        choices=["recommend", "recent", "price_asc", "price_desc"],
        default="recommend",
        help="ì •ë ¬ ê¸°ì¤€ (ê¸°ë³¸: recommend)",
    )
    parser.add_argument("--category", type=int, default=None, help="ì¹´í…Œê³ ë¦¬ ì½”ë“œ")
    parser.add_argument("--min-price", type=int, default=0, help="ìµœì†Œ ê°€ê²©")
    parser.add_argument("--max-price", type=int, default=100_000_000, help="ìµœëŒ€ ê°€ê²©")
    parser.add_argument("--include-sold", action="store_true", help="íŒë§¤ì™„ë£Œ í¬í•¨")
    parser.add_argument("--json", action="store_true", dest="json_output", help="JSON í˜•ì‹ ì¶œë ¥")
    parser.add_argument("--no-url", action="store_true", help="URL ë¯¸í‘œì‹œ")
    parser.add_argument("--delay", type=float, default=1.0, help="ìš”ì²­ ê°„ ëŒ€ê¸°ì‹œê°„(ì´ˆ)")
    parser.add_argument("--detail", type=int, default=None, help="ìƒí’ˆ IDë¡œ ìƒì„¸ ì¡°íšŒ")

    args = parser.parse_args()

    scraper = JoongnaScraper(delay=args.delay)

    # ìƒì„¸ ì¡°íšŒ ëª¨ë“œ
    if args.detail:
        print(f"\nìƒí’ˆ #{args.detail} ìƒì„¸ ì¡°íšŒ ì¤‘...")
        detail = scraper.get_product_detail(args.detail)
        if detail:
            print(json.dumps(detail, ensure_ascii=False, indent=2))
        else:
            print("ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê²€ìƒ‰ ëª¨ë“œ
    search_kwargs = {
        "count": args.count,
        "sort": args.sort,
        "category": args.category,
        "min_price": args.min_price,
        "max_price": args.max_price,
        "exclude_sold": not args.include_sold,
    }

    print(f"\nğŸ” '{args.keyword}' ê²€ìƒ‰ ì¤‘...\n")

    if args.pages > 0:
        results = scraper.search_all(args.keyword, max_pages=args.pages, **search_kwargs)
    else:
        results = scraper.search(args.keyword, page=args.page, **search_kwargs)

    if not results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(0)

    # ì¶œë ¥
    if args.json_output:
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        print(JoongnaScraper.format_results(results, show_url=not args.no_url))

    print(f"\nì´ {len(results)}ê°œ ê²°ê³¼")


if __name__ == "__main__":
    main()
