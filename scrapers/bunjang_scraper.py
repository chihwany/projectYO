"""
ë²ˆê°œì¥í„° (Bunjang) ìŠ¤í¬ë˜í¼
m.bunjang.co.kr / api.bunjang.co.kr ë§¤ë¬¼ì„ ê²€ìƒ‰í•˜ê³  ì¡°íšŒí•˜ëŠ” ëª¨ë“ˆ
"""

import requests
import json
import time
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from urllib.parse import quote
from typing import Optional


class BunjangScraper:
    """ë²ˆê°œì¥í„° ë§¤ë¬¼ ìŠ¤í¬ë˜í¼"""

    BASE_URL = "https://m.bunjang.co.kr"
    # ë²ˆê°œì¥í„° ê³µê°œ ê²€ìƒ‰ API
    SEARCH_API_URL = "https://api.bunjang.co.kr/api/1/find_v2.json"

    SORT_MAP = {
        "recommend": "score",
        "recent": "date",
        "price_asc": "price",
        "price_desc": "price_desc",
    }

    CATEGORY_MAP = {
        310: "ì—¬ì„±ì˜ë¥˜", 320: "ë‚¨ì„±ì˜ë¥˜", 300: "íŒ¨ì…˜ì¡í™”",
        400: "ë·°í‹°", 500: "ì¶œì‚°/ìœ ì•„ë™",
        600: "ëª¨ë°”ì¼/íƒœë¸”ë¦¿", 601: "ìŠ¤ë§ˆíŠ¸í°", 602: "íƒœë¸”ë¦¿",
        700: "ê°€ì „ì œí’ˆ", 800: "ë…¸íŠ¸ë¶/PC",
        900: "ì¹´ë©”ë¼", 110: "ê°€êµ¬/ì¸í…Œë¦¬ì–´",
        120: "ë¦¬ë¹™/ìƒí™œ", 130: "ê²Œì„",
        140: "ë°˜ë ¤ë™ë¬¼/ì·¨ë¯¸", 150: "ë„ì„œ/ìŒë°˜/ë¬¸êµ¬",
        160: "í‹°ì¼“/ì¿ í°", 170: "ìŠ¤í¬ì¸ /ë ˆì €",
        180: "ìë™ì°¨/ì˜¤í† ë°”ì´",
    }

    # ë²ˆê°œì¥í„° ì¹´í…Œê³ ë¦¬ API
    CATEGORIES_API_URL = "https://api.bunjang.co.kr/api/1/categories/list.json"

    # ì¹´í…Œê³ ë¦¬ ìºì‹œ (ëŸ°íƒ€ì„ ì¤‘ APIì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ)
    _api_categories_cache: Optional[dict] = None  # {id: {id, title, parent_id, depth, children: [...]}}
    _api_top_categories_cache: Optional[list] = None  # ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ ëª©ë¡

    # â”€â”€ í•˜ìœ„(ì¤‘ë¶„ë¥˜) ì¹´í…Œê³ ë¦¬ â”€â”€
    # find_v2 APIë¡œ í‚¤ì›Œë“œ ì—†ì´ ìµœê·¼ ë§¤ë¬¼ì„ ì¡°íšŒí•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì¹´í…Œê³ ë¦¬.
    # ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì¼ë¶€ëŠ” í•˜ìœ„ ì¹´í…Œê³ ë¦¬ê°€ ì—†ì–´ë„ ì¡°íšŒ ê°€ëŠ¥í•˜ì§€ë§Œ,
    # ì¼ë¶€(160 ë“±)ëŠ” ë°˜ë“œì‹œ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    SUBCATEGORY_MAP = {
        # ì—¬ì„±ì˜ë¥˜ (310)
        310100: "ì—¬ì„± ìƒì˜", 310200: "ì—¬ì„± í•˜ì˜", 310300: "ì—¬ì„± ì›í”¼ìŠ¤/ìŠ¤ì»¤íŠ¸",
        310400: "ì—¬ì„± ì•„ìš°í„°", 310500: "ì—¬ì„± ì •ì¥/ì„¸íŠ¸",
        # ë‚¨ì„±ì˜ë¥˜ (320)
        320100: "ë‚¨ì„± ìƒì˜", 320200: "ë‚¨ì„± í•˜ì˜", 320300: "ë‚¨ì„± ì•„ìš°í„°",
        320400: "ë‚¨ì„± ì •ì¥/ì„¸íŠ¸",
        # íŒ¨ì…˜ì¡í™” (300)
        300100: "ì‹ ë°œ", 300200: "ê°€ë°©", 300300: "ì‹œê³„",
        300400: "íŒ¨ì…˜ì•¡ì„¸ì„œë¦¬", 300500: "ëª¨ì",
        # ë·°í‹° (400)
        400100: "ìŠ¤í‚¨ì¼€ì–´", 400200: "ë©”ì´í¬ì—…", 400300: "í—¤ì–´ì¼€ì–´",
        400400: "ë°”ë””ì¼€ì–´", 400500: "í–¥ìˆ˜",
        # ì¶œì‚°/ìœ ì•„ë™ (500)
        500100: "ìœ ì•„ë™ ì˜ë¥˜", 500200: "ìœ ì•„ìš©í’ˆ", 500300: "ì¶œì‚°ìš©í’ˆ",
        500400: "ìœ ì•„ë™ ì¥ë‚œê°",
        # ëª¨ë°”ì¼/íƒœë¸”ë¦¿ (600)
        601: "ìŠ¤ë§ˆíŠ¸í°", 602: "íƒœë¸”ë¦¿", 600300: "ëª¨ë°”ì¼ ì•¡ì„¸ì„œë¦¬",
        600400: "ì›¨ì–´ëŸ¬ë¸”",
        # ê°€ì „ì œí’ˆ (700)
        700100: "ì£¼ë°©ê°€ì „", 700200: "ìƒí™œê°€ì „", 700300: "ê³„ì ˆê°€ì „",
        700400: "ì˜ìƒê°€ì „", 700500: "ìŒí–¥ê°€ì „",
        # ë…¸íŠ¸ë¶/PC (800)
        800100: "ë…¸íŠ¸ë¶", 800200: "ë°ìŠ¤í¬íƒ‘", 800300: "PC ë¶€í’ˆ",
        800400: "ëª¨ë‹ˆí„°", 800500: "PC ì£¼ë³€ê¸°ê¸°",
        # ì¹´ë©”ë¼ (900)
        900100: "ë””ì§€í„¸ì¹´ë©”ë¼", 900200: "ìº ì½”ë”", 900300: "ë Œì¦ˆ",
        900400: "ì¹´ë©”ë¼ ì•¡ì„¸ì„œë¦¬",
        # ê°€êµ¬/ì¸í…Œë¦¬ì–´ (110)
        110100: "ì¹¨ëŒ€/ë§¤íŠ¸ë¦¬ìŠ¤", 110200: "ì±…ìƒ/í…Œì´ë¸”", 110300: "ì˜ì/ì†ŒíŒŒ",
        110400: "ìˆ˜ë‚©/ì„ ë°˜", 110500: "ì¸í…Œë¦¬ì–´ ì†Œí’ˆ",
        # ë¦¬ë¹™/ìƒí™œ (120)
        120100: "ì£¼ë°©ìš©í’ˆ", 120200: "ìš•ì‹¤ìš©í’ˆ", 120300: "ì²­ì†Œìš©í’ˆ",
        120400: "ì„¸íƒìš©í’ˆ", 120500: "ìƒí™œì¡í™”",
        # ê²Œì„ (130)
        130100: "ê²Œì„ê¸°", 130200: "ê²Œì„ íƒ€ì´í‹€", 130300: "ê²Œì„ ì•¡ì„¸ì„œë¦¬",
        # ë°˜ë ¤ë™ë¬¼/ì·¨ë¯¸ (140)
        140100: "ë°˜ë ¤ë™ë¬¼ìš©í’ˆ", 140200: "í‚¤ëœíŠ¸/í”¼ê·œì–´", 140300: "í•¸ë“œë©”ì´ë“œ",
        140400: "ì•…ê¸°", 140500: "ì‹ë¬¼",
        # ë„ì„œ/ìŒë°˜/ë¬¸êµ¬ (150)
        150100: "ë„ì„œ", 150200: "ìŒë°˜/DVD", 150300: "ë¬¸êµ¬",
        150400: "ì•„ì´ëŒ êµ¿ì¦ˆ",
        # í‹°ì¼“/ì¿ í° (160)
        160100: "í‹°ì¼“", 160200: "ì¿ í°", 160300: "ìƒí’ˆê¶Œ",
        # ìŠ¤í¬ì¸ /ë ˆì € (170)
        170100: "ê³¨í”„", 170200: "ìº í•‘", 170300: "ìì „ê±°",
        170400: "í—¬ìŠ¤/ìš”ê°€", 170500: "ìˆ˜ìƒìŠ¤í¬ì¸ ",
        170600: "ìŠ¤í‚¤/ë³´ë“œ", 170700: "ë“±ì‚°/ì•„ì›ƒë„ì–´",
        # ìë™ì°¨/ì˜¤í† ë°”ì´ (180)
        180100: "ìë™ì°¨", 180200: "ì˜¤í† ë°”ì´", 180300: "ìë™ì°¨ ìš©í’ˆ",
    }

    def __init__(self, delay: float = 1.0):
        """
        Args:
            delay: ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
        """
        self.delay = delay
        self._subcategory_cache: Optional[dict] = None  # ë™ì  ì¹´í…Œê³ ë¦¬ ìºì‹œ
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Referer": "https://m.bunjang.co.kr/",
            "Origin": "https://m.bunjang.co.kr",
        })
        self._last_request_time = 0

    def _throttle(self):
        """ìš”ì²­ ê°„ê²© ì œí•œ"""
        elapsed = time.time() - self._last_request_time
        if elapsed < self.delay:
            time.sleep(self.delay - elapsed)
        self._last_request_time = time.time()

    def _parse_item(self, item: dict) -> dict:
        """ìƒí’ˆ ì•„ì´í…œ íŒŒì‹±"""
        pid = str(item.get("pid", item.get("product_id", "")))

        # ê°€ê²©
        price = item.get("price", "0")
        if isinstance(price, str):
            price = int(re.sub(r'[^\d]', '', price) or 0)
        else:
            price = int(price)

        # ì´ë¯¸ì§€
        image_url = ""
        if item.get("product_image"):
            image_url = item["product_image"]
        elif item.get("image"):
            image_url = item["image"]
        elif item.get("img"):
            image_url = item["img"]

        # ìƒíƒœ
        status_raw = item.get("status", "")
        if status_raw in ("0", 0, "íŒë§¤ì¤‘"):
            status = "íŒë§¤ì¤‘"
        elif status_raw in ("1", 1, "ì˜ˆì•½ì¤‘"):
            status = "ì˜ˆì•½ì¤‘"
        elif status_raw in ("2", 2, "íŒë§¤ì™„ë£Œ"):
            status = "íŒë§¤ì™„ë£Œ"
        elif status_raw in ("3", 3):
            status = "ìˆ¨ê¹€"
        else:
            status = str(status_raw) if status_raw else "íŒë§¤ì¤‘"

        # ì‹œê°„
        update_time = item.get("update_time", item.get("updated_at", ""))
        if isinstance(update_time, (int, float)) and update_time > 0:
            try:
                from datetime import datetime
                update_time = datetime.fromtimestamp(update_time).strftime("%Y-%m-%d %H:%M")
            except (OSError, ValueError):
                update_time = str(update_time)

        return {
            "id": pid,
            "title": item.get("name", item.get("title", "")),
            "price": price,
            "price_str": f"{price:,}ì›" if price > 0 else "ê°€ê²©ë¯¸ì •",
            "image_url": image_url,
            "status": status,
            "location": item.get("location", item.get("area", "")),
            "time": update_time,
            "url": f"{self.BASE_URL}/product/{pid}",
            "seller": item.get("seller_name", item.get("store_name", "")),
            "likes": item.get("wish_cnt", item.get("like_count", 0)),
            "views": item.get("view_cnt", item.get("view_count", 0)),
            "safe_payment": item.get("safe_payment", item.get("bunpay", False)),
            "category": item.get("category_name", ""),
            "free_shipping": item.get("free_shipping", False),
        }

    def search(
        self,
        keyword: str,
        page: int = 1,
        count: int = 20,
        sort: str = "recommend",
        category: Optional[int] = None,
        min_price: Optional[int] = None,
        max_price: Optional[int] = None,
        exclude_sold: bool = True,
    ) -> list[dict]:
        """
        ë²ˆê°œì¥í„° ë§¤ë¬¼ ê²€ìƒ‰

        Args:
            keyword: ê²€ìƒ‰ì–´
            page: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
            count: í•œ í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜ (ìµœëŒ€ 100)
            sort: ì •ë ¬ ê¸°ì¤€ (recommend, recent, price_asc, price_desc)
            category: ì¹´í…Œê³ ë¦¬ ì½”ë“œ (Noneì´ë©´ ì „ì²´)
            min_price: ìµœì†Œ ê°€ê²©
            max_price: ìµœëŒ€ ê°€ê²©
            exclude_sold: íŒë§¤ì™„ë£Œ ì œì™¸ ì—¬ë¶€

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        self._throttle()

        sort_value = self.SORT_MAP.get(sort, "score")
        api_page = page - 1  # ë²ˆê°œì¥í„° APIëŠ” 0-based

        params = {
            "q": keyword,
            "order": sort_value,
            "page": api_page,
            "n": min(count, 100),
            "stat": "v2",
        }

        if category:
            params["category"] = category
        if min_price is not None and min_price > 0:
            params["price_min"] = min_price
        if max_price is not None:
            params["price_max"] = max_price
        if exclude_sold:
            params["req_ref"] = "search"
            params["stat_status"] = "s"

        try:
            response = self.session.get(
                self.SEARCH_API_URL, params=params, timeout=15
            )
            response.raise_for_status()
            data = response.json()
        except requests.RequestException as e:
            print(f"[ì˜¤ë¥˜] API ìš”ì²­ ì‹¤íŒ¨: {e}")
            # í´ë°±: ì›¹ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
            return self._search_fallback(keyword, page, count, sort)
        except json.JSONDecodeError:
            print("[ì˜¤ë¥˜] JSON íŒŒì‹± ì‹¤íŒ¨. ì›¹ í˜ì´ì§€ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            return self._search_fallback(keyword, page, count, sort)

        items_raw = data.get("list", data.get("items", []))
        total = data.get("num_found", data.get("total", 0))

        results = []
        for item in items_raw:
            parsed = self._parse_item(item)
            if parsed["title"]:
                # íŒë§¤ì™„ë£Œ í•„í„° (APIì—ì„œ ì•ˆ ê±¸ëŸ¬ì§„ ê²½ìš° ëŒ€ë¹„)
                if exclude_sold and parsed["status"] == "íŒë§¤ì™„ë£Œ":
                    continue
                results.append(parsed)

        if results:
            print(f"[ê²€ìƒ‰ì™„ë£Œ] '{keyword}' - ì´ {total}ê°œ ì¤‘ {len(results)}ê°œ ì¡°íšŒ")
        else:
            print(f"[ê²€ìƒ‰ì™„ë£Œ] '{keyword}' - ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (total={total})")

        return results

    def _search_fallback(
        self, keyword: str, page: int, count: int, sort: str
    ) -> list[dict]:
        """
        API ì‹¤íŒ¨ ì‹œ ì›¹ í˜ì´ì§€ì—ì„œ __NEXT_DATA__ íŒŒì‹±ìœ¼ë¡œ í´ë°±
        """
        self._throttle()
        encoded = quote(keyword)
        url = f"{self.BASE_URL}/search/products?q={encoded}&page={page}"
        if sort != "recommend":
            sort_value = self.SORT_MAP.get(sort, "score")
            url += f"&order={sort_value}"

        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"[ì˜¤ë¥˜] ì›¹ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return []

        # __NEXT_DATA__ ì¶”ì¶œ
        match = re.search(
            r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>',
            response.text, re.DOTALL
        )
        if not match:
            print("[ì˜¤ë¥˜] í˜ì´ì§€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        try:
            next_data = json.loads(match.group(1))
        except json.JSONDecodeError:
            print("[ì˜¤ë¥˜] JSON íŒŒì‹± ì‹¤íŒ¨")
            return []

        # dehydratedStateì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        queries = (
            next_data.get("props", {})
            .get("pageProps", {})
            .get("dehydratedState", {})
            .get("queries", [])
        )

        items_raw = []
        for q in queries:
            state_data = q.get("state", {}).get("data", {})
            if isinstance(state_data, dict):
                # pages êµ¬ì¡° (infinite query)
                pages = state_data.get("pages", [])
                for p in pages:
                    items_raw.extend(p.get("list", p.get("items", [])))
                # flat êµ¬ì¡°
                if not items_raw:
                    items_raw = state_data.get("list", state_data.get("items", []))

        results = []
        for item in items_raw[:count]:
            parsed = self._parse_item(item)
            if parsed["title"]:
                results.append(parsed)

        print(f"[ê²€ìƒ‰ì™„ë£Œ-í´ë°±] '{keyword}' - {len(results)}ê°œ ì¡°íšŒ")
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì¹´í…Œê³ ë¦¬ë³„ ìµœê·¼ ë§¤ë¬¼ ìˆ˜ì§‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë²ˆê°œì¥í„° ê³µì‹ ì¹´í…Œê³ ë¦¬ API ì—°ë™
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def fetch_categories(self, use_cache: bool = True) -> dict:
        """
        ë²ˆê°œì¥í„° ê³µì‹ ì¹´í…Œê³ ë¦¬ APIì—ì„œ ì „ì²´ ì¹´í…Œê³ ë¦¬ íŠ¸ë¦¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

        Returns:
            {
              "top_categories": [{id, title, count, icon_url, children: [...]}, ...],
              "flat": {id: {id, title, count, parent_id, depth, icon_url}, ...}
            }
        """
        if use_cache and BunjangScraper._api_categories_cache is not None:
            return {
                "top_categories": BunjangScraper._api_top_categories_cache,
                "flat": BunjangScraper._api_categories_cache,
            }

        self._throttle()
        try:
            response = self.session.get(self.CATEGORIES_API_URL, timeout=15)
            response.raise_for_status()
            data = response.json()
        except (requests.RequestException, json.JSONDecodeError) as e:
            print(f"[ì¹´í…Œê³ ë¦¬ API ì˜¤ë¥˜] {e}")
            return {"top_categories": [], "flat": {}}

        if data.get("result") != "success":
            print(f"[ì¹´í…Œê³ ë¦¬ API ì˜¤ë¥˜] result={data.get('result')}")
            return {"top_categories": [], "flat": {}}

        flat: dict = {}
        top_categories = []

        def _parse_node(node: dict, parent_id: Optional[str], depth: int) -> dict:
            cat_id = str(node["id"])
            children_raw = node.get("categories", [])
            children_parsed = [_parse_node(c, cat_id, depth + 1) for c in children_raw]

            entry = {
                "id": cat_id,
                "title": node.get("title", ""),
                "count": node.get("count", 0),
                "parent_id": parent_id,
                "depth": depth,
                "icon_url": node.get("icon_url", ""),
                "children": children_parsed,
            }
            flat[cat_id] = {
                k: v for k, v in entry.items() if k != "children"
            }
            flat[cat_id]["children"] = [c["id"] for c in children_parsed]
            return entry

        for top in data.get("categories", []):
            top_categories.append(_parse_node(top, None, 0))

        BunjangScraper._api_categories_cache = flat
        BunjangScraper._api_top_categories_cache = top_categories

        print(f"[ì¹´í…Œê³ ë¦¬ ë¡œë“œ] ìµœìƒë‹¨ {len(top_categories)}ê°œ, ì „ì²´ {len(flat)}ê°œ")
        return {"top_categories": top_categories, "flat": flat}

    def get_top_categories(self, use_cache: bool = True) -> list[dict]:
        """
        ë²ˆê°œì¥í„° ìµœìƒë‹¨(depth=0) ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            [{id, title, count, icon_url, children: [í•˜ìœ„ì¹´í…Œê³ ë¦¬...]}, ...]
        """
        result = self.fetch_categories(use_cache=use_cache)
        return result["top_categories"]

    def get_recent_by_top_categories(
        self,
        count: int = 20,
        top_category_ids: Optional[list] = None,
        min_price: Optional[int] = None,
        max_price: Optional[int] = None,
        exclude_sold: bool = True,
        max_workers: int = 5,
        within_minutes: Optional[int] = None,
        use_cache: bool = True,
    ) -> dict:
        """
        ë²ˆê°œì¥í„° ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ë³„ ìµœê·¼ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ â†’ 2ë‹¨ê³„(ì¤‘ë¶„ë¥˜) ì¹´í…Œê³ ë¦¬ ì½”ë“œë¡œ APIë¥¼ í˜¸ì¶œí•´
        ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìµœê·¼ ë§¤ë¬¼ì„ ë³‘ë ¬ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

        Args:
            count              : ê° ì¤‘ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬ë‹¹ ìˆ˜ì§‘ ê°œìˆ˜ (ê¸°ë³¸ 20, ìµœëŒ€ 100)
            top_category_ids   : ì¡°íšŒí•  ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ id ë¦¬ìŠ¤íŠ¸ (str). Noneì´ë©´ ì „ì²´.
            min_price          : ìµœì†Œ ê°€ê²©
            max_price          : ìµœëŒ€ ê°€ê²©
            exclude_sold       : íŒë§¤ì™„ë£Œ ì œì™¸
            max_workers        : ë³‘ë ¬ ìŠ¤ë ˆë“œ ìˆ˜
            within_minutes     : Në¶„ ì´ë‚´ ë§¤ë¬¼ë§Œ ë°˜í™˜
            use_cache          : ì¹´í…Œê³ ë¦¬ API ìºì‹œ ì‚¬ìš© ì—¬ë¶€

        Returns:
            {
              "top_categories": [
                {
                  "id": "310",
                  "title": "ì—¬ì„±ì˜ë¥˜",
                  "count": ...,       # ë²ˆê°œì¥í„° ì´ ë§¤ë¬¼ ìˆ˜
                  "icon_url": "...",
                  "listings": [{...}, ...],  # ìµœê·¼ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸
                  "listings_count": 42,
                },
                ...
              ],
              "total_listings": 500,
              "elapsed_seconds": 3.2,
            }
        """
        import time as _time
        start = _time.time()

        cat_data = self.fetch_categories(use_cache=use_cache)
        top_cats = cat_data["top_categories"]
        flat = cat_data["flat"]

        # ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        if top_category_ids:
            top_cats = [c for c in top_cats if str(c["id"]) in [str(x) for x in top_category_ids]]

        per_cat = min(count, 100)
        print(
            f"[ë²ˆê°œì¥í„°-ì¹´í…Œê³ ë¦¬ë³„ìµœê·¼ë§¤ë¬¼] ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ {len(top_cats)}ê°œ ìˆ˜ì§‘ ì‹œì‘ "
            f"(ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ {per_cat}ê°œ, workers={max_workers})"
        )

        # ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ idë¥¼ ì§ì ‘ f_category_idë¡œ ì‚¬ìš©
        from collections import defaultdict
        top_results: dict = defaultdict(list)
        seen_ids: set = set()

        def _fetch_top(top_node: dict) -> tuple[str, list[dict]]:
            top_id = str(top_node["id"])
            items = self._fetch_category_recent(
                int(top_id),
                page=0,
                count=per_cat,
                min_price=min_price,
                max_price=max_price,
                exclude_sold=exclude_sold,
                use_f_category=True,
            )
            return top_id, items

        with ThreadPoolExecutor(max_workers=max_workers) as pool:
            futures = {pool.submit(_fetch_top, top): str(top["id"]) for top in top_cats}
            for future in as_completed(futures):
                try:
                    top_id, items = future.result()
                    for item in items:
                        item_id = item.get("id")
                        if item_id and item_id not in seen_ids:
                            seen_ids.add(item_id)
                            top_results[top_id].append(item)
                except Exception as e:
                    top_id = futures[future]
                    print(f"  [ì˜¤ë¥˜] top={top_id}: {e}")

        # ì‹œê°„ í•„í„°
        if within_minutes is not None:
            cutoff = datetime.now() - timedelta(minutes=within_minutes)
            for top_id in top_results:
                before = len(top_results[top_id])
                top_results[top_id] = [
                    r for r in top_results[top_id] if self._parse_dt(r) >= cutoff
                ]
                after = len(top_results[top_id])
                if before != after:
                    print(f"  [ì‹œê°„í•„í„°] top={top_id}: {before}â†’{after}")

        # ê° ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ìµœì‹ ìˆœ ì •ë ¬
        for top_id in top_results:
            top_results[top_id].sort(key=self._parse_dt, reverse=True)

        # ê²°ê³¼ ì¡°ë¦½
        total = 0
        output_cats = []
        for top in top_cats:
            top_id = str(top["id"])
            listings = top_results.get(top_id, [])
            total += len(listings)
            output_cats.append({
                "id": top_id,
                "title": top["title"],
                "count": top.get("count", 0),
                "icon_url": top.get("icon_url", ""),
                "listings": listings,
                "listings_count": len(listings),
            })

        elapsed = round(_time.time() - start, 2)
        print(f"[ë²ˆê°œì¥í„°-ì¹´í…Œê³ ë¦¬ë³„ìµœê·¼ë§¤ë¬¼] ì™„ë£Œ - ì´ {total}ê°œ ({elapsed}ì´ˆ)")

        return {
            "top_categories": output_cats,
            "total_listings": total,
            "elapsed_seconds": elapsed,
        }

    def _expand_to_subcategories(self, categories: list[int]) -> list[int]:
        """
        ìƒìœ„ ì¹´í…Œê³ ë¦¬ ì½”ë“œë¥¼ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì½”ë“œë¡œ í™•ì¥í•©ë‹ˆë‹¤.

        ì˜ˆ: [160] â†’ [160100, 160200, 160300]
        ì´ë¯¸ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ì¸ ì½”ë“œ(ì˜ˆ: 160100)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
        ìƒìœ„ë„ í•˜ìœ„ë„ ì•„ë‹Œ ì•Œ ìˆ˜ ì—†ëŠ” ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ í¬í•¨í•©ë‹ˆë‹¤(APIì—ì„œ ê±¸ëŸ¬ì§).
        """
        expanded = []
        for cat in categories:
            if cat in self.SUBCATEGORY_MAP:
                # ì´ë¯¸ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                expanded.append(cat)
            elif cat in self.CATEGORY_MAP:
                # ìƒìœ„ ì¹´í…Œê³ ë¦¬ â†’ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë“¤ë¡œ í™•ì¥
                cat_prefix = str(cat)
                children = [
                    sub_code for sub_code in self.SUBCATEGORY_MAP
                    if str(sub_code).startswith(cat_prefix) and sub_code != cat
                ]
                if children:
                    expanded.extend(children)
                    print(f"  [ì¹´í…Œê³ ë¦¬ í™•ì¥] {self.CATEGORY_MAP[cat]}({cat}) â†’ í•˜ìœ„ {len(children)}ê°œ")
                else:
                    # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ê°€ ë§µì— ì—†ìœ¼ë©´ ì›ë³¸ ì½”ë“œ ì‹œë„
                    expanded.append(cat)
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” ì½”ë“œ â†’ ê·¸ëŒ€ë¡œ ì‹œë„
                expanded.append(cat)
        return expanded

    def _fetch_category_recent(
        self,
        category: int,
        page: int = 0,
        count: int = 100,
        min_price: Optional[int] = None,
        max_price: Optional[int] = None,
        exclude_sold: bool = True,
        use_f_category: bool = False,
    ) -> list[dict]:
        """
        ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ì˜ ìµœê·¼ ë§¤ë¬¼ì„ APIë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.

        use_f_category=True ì´ë©´ f_category_id íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        (popular_category ë°©ì‹ - ìµœìƒë‹¨ ì¹´í…Œê³ ë¦¬ id ì§ì ‘ ì¡°íšŒì— ì‚¬ìš©)
        """
        self._throttle()

        import time as _t
        request_id = int(_t.time())

        if use_f_category:
            params = {
                "f_category_id": category,
                "page": page,
                "order": "date",
                "req_ref": "popular_category",
                "request_id": request_id,
                "stat_device": "w",
                "n": min(count, 100),
                "version": 4,
            }
        else:
            params = {
                "order": "date",
                "page": page,
                "n": min(count, 100),
                "stat": "v2",
                "category": category,
            }

        if min_price is not None and min_price > 0:
            params["price_min"] = min_price
        if max_price is not None:
            params["price_max"] = max_price
        if exclude_sold and not use_f_category:
            params["req_ref"] = "search"
            params["stat_status"] = "s"

        cat_name = (
            self.SUBCATEGORY_MAP.get(category)
            or self.CATEGORY_MAP.get(category)
            or str(category)
        )

        try:
            response = self.session.get(
                self.SEARCH_API_URL, params=params, timeout=15
            )
            # 400 ì—ëŸ¬: ìƒìœ„ ì¹´í…Œê³ ë¦¬ë¡œ ì¡°íšŒ ì‹œ ERR_INVALID_PARAMETER ë°œìƒ
            if response.status_code == 400:
                try:
                    err = response.json()
                    reason = err.get("reason", "")
                except Exception:
                    reason = response.text[:200]
                print(f"  [ì¹´í…Œê³ ë¦¬:{cat_name}({category})] API 400 ì—ëŸ¬ - {reason} (skip)")
                return []
            response.raise_for_status()
            data = response.json()
        except (requests.RequestException, json.JSONDecodeError) as e:
            print(f"  [ì¹´í…Œê³ ë¦¬:{cat_name}({category})] API ìš”ì²­ ì‹¤íŒ¨: {e}")
            return []

        items_raw = data.get("list", data.get("items", []))

        results = []
        for item in items_raw:
            parsed = self._parse_item(item)
            if parsed["title"]:
                if exclude_sold and parsed["status"] == "íŒë§¤ì™„ë£Œ":
                    continue
                if not parsed["category"]:
                    parsed["category"] = cat_name
                results.append(parsed)

        print(f"  [ì¹´í…Œê³ ë¦¬:{cat_name}({category})] {len(results)}ê°œ ìˆ˜ì§‘")
        return results

    @staticmethod
    def _parse_dt(item: dict) -> datetime:
        """ë§¤ë¬¼ì˜ ë“±ë¡/ìˆ˜ì • ì‹œê°„ì„ datetimeìœ¼ë¡œ íŒŒì‹±"""
        raw = str(item.get("time") or "").strip().rstrip("Z")
        for fmt in (
            "%Y-%m-%dT%H:%M:%S",
            "%Y-%m-%dT%H:%M",
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
        ):
            try:
                return datetime.strptime(raw, fmt)
            except ValueError:
                continue
        return datetime.min

    def get_recent_listings(
        self,
        count: int = 100,
        categories: Optional[list] = None,
        min_price: Optional[int] = None,
        max_price: Optional[int] = None,
        exclude_sold: bool = True,
        max_workers: int = 5,
        within_minutes: Optional[int] = None,
    ) -> list[dict]:
        """
        ì „ì²´ ì¹´í…Œê³ ë¦¬ì˜ ìµœì‹  ë§¤ë¬¼ì„ ë³‘ë ¬ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

        ë²ˆê°œì¥í„° find_v2 APIì— í‚¤ì›Œë“œ ì—†ì´ category + order=date ë¡œ
        ê° ì¹´í…Œê³ ë¦¬ì˜ ìµœì‹  ë§¤ë¬¼ì„ ê°€ì ¸ì˜¨ ë’¤ í†µí•©Â·ì •ë ¬í•©ë‹ˆë‹¤.

        ìƒìœ„ ì¹´í…Œê³ ë¦¬(310, 160 ë“±)ë¡œëŠ” í‚¤ì›Œë“œ ì—†ëŠ” ì¡°íšŒê°€ ë¶ˆê°€í•˜ë¯€ë¡œ,
        ê¸°ë³¸ì ìœ¼ë¡œ SUBCATEGORY_MAP(í•˜ìœ„ ì¹´í…Œê³ ë¦¬)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        categories íŒŒë¼ë¯¸í„°ë¡œ ì§ì ‘ ì§€ì •í•œ ê²½ìš° í•´ë‹¹ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©°,
        API 400 ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.

        Args:
            count         : ì¹´í…Œê³ ë¦¬ë‹¹ ìˆ˜ì§‘ ê°œìˆ˜ (ê¸°ë³¸ 100, ìµœëŒ€ 100)
            categories    : ì¡°íšŒí•  ì¹´í…Œê³ ë¦¬ ì½”ë“œ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ ì „ì²´ í•˜ìœ„ ì¹´í…Œê³ ë¦¬.
            min_price     : ìµœì†Œ ê°€ê²©
            max_price     : ìµœëŒ€ ê°€ê²©
            exclude_sold  : íŒë§¤ì™„ë£Œ ì œì™¸ (ê¸°ë³¸ True)
            max_workers   : ë³‘ë ¬ ìŠ¤ë ˆë“œ ìˆ˜ (ê¸°ë³¸ 5)
            within_minutes: ì§€ì • ì‹œ, í˜„ì¬ ì‹œê° ê¸°ì¤€ Në¶„ ì´ë‚´ ë“±ë¡ëœ ë§¤ë¬¼ë§Œ ë°˜í™˜.

        Returns:
            ìˆ˜ì§‘ëœ ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ (ë“±ë¡ ì‹œê°„ ìµœì‹ ìˆœ ì •ë ¬)
        """
        start = time.time()
        # categories ì§€ì • ì‹œ í•´ë‹¹ ì½”ë“œ ì‚¬ìš©, ì•„ë‹ˆë©´ ì „ì²´ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
        if categories:
            target_cats = self._expand_to_subcategories(categories)
        else:
            target_cats = list(self.SUBCATEGORY_MAP.keys())
        per_cat = min(count, 100)

        print(
            f"[ë²ˆê°œì¥í„°-ìµœê·¼ë§¤ë¬¼] ì¹´í…Œê³ ë¦¬ {len(target_cats)}ê°œ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘ "
            f"(ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ {per_cat}ê°œ, workers={max_workers}"
            + (f", ìµœê·¼ {within_minutes}ë¶„ ì´ë‚´" if within_minutes else "")
            + ")"
        )

        all_results: list[dict] = []
        seen_ids: set = set()

        def _fetch(cat: int) -> list[dict]:
            return self._fetch_category_recent(
                cat, page=0, count=per_cat,
                min_price=min_price, max_price=max_price,
                exclude_sold=exclude_sold,
            )

        with ThreadPoolExecutor(max_workers=max_workers) as pool:
            futures = {pool.submit(_fetch, c): c for c in target_cats}
            for future in as_completed(futures):
                try:
                    for item in future.result():
                        item_id = item.get("id")
                        if item_id and item_id not in seen_ids:
                            seen_ids.add(item_id)
                            all_results.append(item)
                except Exception as e:
                    print(f"  [ì¹´í…Œê³ ë¦¬:{futures[future]}] ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

        # ì‹œê°„ í•„í„°
        if within_minutes is not None:
            cutoff = datetime.now() - timedelta(minutes=within_minutes)
            before = len(all_results)
            all_results = [r for r in all_results if self._parse_dt(r) >= cutoff]
            print(f"[ë²ˆê°œì¥í„°-ìµœê·¼ë§¤ë¬¼] ì‹œê°„ í•„í„°({within_minutes}ë¶„): {before}ê°œ â†’ {len(all_results)}ê°œ")

        # ìµœì‹ ìˆœ ì •ë ¬
        all_results.sort(key=self._parse_dt, reverse=True)

        elapsed = round(time.time() - start, 2)
        print(f"[ë²ˆê°œì¥í„°-ìµœê·¼ë§¤ë¬¼] ìµœì¢… {len(all_results)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ - ì¤‘ë³µ ì œê±° í›„ ({elapsed}ì´ˆ)")
        return all_results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë‹¤ì¤‘ í˜ì´ì§€ ê²€ìƒ‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def search_all(
        self,
        keyword: str,
        max_pages: int = 5,
        **kwargs,
    ) -> list[dict]:
        """
        ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì³ ê²€ìƒ‰

        Args:
            keyword: ê²€ìƒ‰ì–´
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            **kwargs: search()ì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì

        Returns:
            ëª¨ë“  í˜ì´ì§€ì˜ ê²€ìƒ‰ ê²°ê³¼
        """
        all_results = []
        for page in range(1, max_pages + 1):
            results = self.search(keyword, page=page, **kwargs)
            if not results:
                break
            all_results.extend(results)
            print(f"  ... {page}í˜ì´ì§€ ì™„ë£Œ (ëˆ„ì  {len(all_results)}ê°œ)")
        return all_results

    @staticmethod
    def format_results(results: list[dict], show_url: bool = True) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…"""
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        lines = []
        lines.append(f"{'='*60}")
        lines.append(f" ë²ˆê°œì¥í„° ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        lines.append(f"{'='*60}")

        for i, item in enumerate(results, 1):
            lines.append(f"\n[{i}] {item['title']}")
            lines.append(f"    ğŸ’° ê°€ê²©: {item['price_str']}")
            if item.get("status"):
                lines.append(f"    ğŸ“Œ ìƒíƒœ: {item['status']}")
            if item.get("location"):
                lines.append(f"    ğŸ“ ì§€ì—­: {item['location']}")
            if item.get("time"):
                lines.append(f"    ğŸ• ë“±ë¡: {item['time']}")
            if item.get("seller"):
                lines.append(f"    ğŸ‘¤ íŒë§¤ì: {item['seller']}")
            if item.get("safe_payment"):
                lines.append(f"    ğŸ”’ ì•ˆì „ê²°ì œ: ì§€ì›")
            if show_url:
                lines.append(f"    ğŸ”— ë§í¬: {item['url']}")
            lines.append(f"    {'â”€'*40}")

        return "\n".join(lines)
